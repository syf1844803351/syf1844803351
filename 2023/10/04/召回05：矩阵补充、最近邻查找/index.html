<!DOCTYPE html><html lang="zh.CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>召回05：矩阵补充、最近邻查找 | 云璟QAQ</title><meta name="author" content="Syf"><meta name="copyright" content="Syf"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本博文引自王树森老师推荐系统。视频地址：召回05：矩阵补充、最近邻查找_哔哩哔哩_bilibili课件地址： https:&#x2F;&#x2F;github.com&#x2F;wangshusen&#x2F;RecommenderSystem  这节课后面几节课详细讲解向量召回，矩阵补充是向量召回最简单的一种方法，不过现在已经不太常用这种方法了，我讲解矩阵补充是为了帮助大家理解下节课的双塔模型，大家可能早就熟悉矩阵补充，但我还是建议">
<meta property="og:type" content="article">
<meta property="og:title" content="召回05：矩阵补充、最近邻查找">
<meta property="og:url" content="https://syf1844803351.github.io/2023/10/04/%E5%8F%AC%E5%9B%9E05%EF%BC%9A%E7%9F%A9%E9%98%B5%E8%A1%A5%E5%85%85%E3%80%81%E6%9C%80%E8%BF%91%E9%82%BB%E6%9F%A5%E6%89%BE/index.html">
<meta property="og:site_name" content="云璟QAQ">
<meta property="og:description" content="本博文引自王树森老师推荐系统。视频地址：召回05：矩阵补充、最近邻查找_哔哩哔哩_bilibili课件地址： https:&#x2F;&#x2F;github.com&#x2F;wangshusen&#x2F;RecommenderSystem  这节课后面几节课详细讲解向量召回，矩阵补充是向量召回最简单的一种方法，不过现在已经不太常用这种方法了，我讲解矩阵补充是为了帮助大家理解下节课的双塔模型，大家可能早就熟悉矩阵补充，但我还是建议">
<meta property="og:locale">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2023-10-04T12:32:10.000Z">
<meta property="article:modified_time" content="2023-10-06T03:11:01.833Z">
<meta property="article:author" content="Syf">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://syf1844803351.github.io/2023/10/04/%E5%8F%AC%E5%9B%9E05%EF%BC%9A%E7%9F%A9%E9%98%B5%E8%A1%A5%E5%85%85%E3%80%81%E6%9C%80%E8%BF%91%E9%82%BB%E6%9F%A5%E6%89%BE/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '召回05：矩阵补充、最近邻查找',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-10-06 11:11:01'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">34</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">2</div></a></div><hr class="custom-hr"/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="云璟QAQ"><span class="site-name">云璟QAQ</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">召回05：矩阵补充、最近邻查找</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-10-04T12:32:10.000Z" title="Created 2023-10-04 20:32:10">2023-10-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-10-06T03:11:01.833Z" title="Updated 2023-10-06 11:11:01">2023-10-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%8E%8B%E6%A0%91%E6%A3%AE%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">王树森推荐系统</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="召回05：矩阵补充、最近邻查找"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>本博文引自王树森老师推荐系统。<br>视频地址：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1b34y1e7En/?spm_id_from=333.880.my_history.page.click&amp;vd_source=c4a0ede13294272753679347b1eb1d75">召回05：矩阵补充、最近邻查找_哔哩哔哩_bilibili</a><br>课件地址： <a target="_blank" rel="noopener" href="https://github.com/wangshusen/RecommenderSystem">https://github.com/wangshusen/RecommenderSystem</a></p>
</blockquote>
<p>这节课后面几节课详细讲解向量召回，矩阵补充是向量召回最简单的一种方法，不过现在已经不太常用这种方法了，我讲解矩阵补充是为了帮助大家理解下节课的双塔模型，大家可能早就熟悉矩阵补充，但我还是建议大家把这节课看完，我会讲很多教科书里没有写，但是在工业界非常有用的知识点。</p>
<h2 id="复习"><a href="#复习" class="headerlink" title="复习"></a>复习</h2><p>上节课介绍了$embedding$，他可以把用户ID或者物品ID映射成向量，我画的这个模型就是基于$embedding$做推荐，模型的输入是一个用户ID和一个物品ID，模型的输出是一个实数，是用户对物品兴趣的预估值，这个数越大，表示用户对物品越感兴趣。<br>下面我们看一下模型的结构，左边的结构只有一个$embedding$层，把一个用户ID映射到一个向量，记住向量a这个向量是对用户的表征，回忆一下上节课的内容，<strong>$embedding$层的参数是一个矩阵，矩阵中列的数量是用户数量</strong>，每一列都是图中a这么大的向量，$embedding$层的参数数量等于用户数量乘以向量a的大小。右边的结构是另一个$embedding$层，把一个物品ID映射到一个向量，记作b，大小跟向量a设置成一样的，向量b是对物品的表征，$embedding$层的参数是一个矩阵，输出的向量b是矩阵的一列，矩阵中列的数量是物品的数量。模型一共用了两个$embedding$层，它们不共享参数，对向量a和b求内积，得到一个实数作为模型的输出，这个模型就是矩阵补充模型，接下来我会解释为什么这个模型叫做矩阵补充。<br><img src="/images/8_embedding_1.png" alt="8_embedding_1"></p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><h3 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h3><p>刚才定义了模型结构，接下来要讲模型的训练，首先讲训练的基本思路.</p>
<ul>
<li>用户$embedding$层的参数是一个矩阵，记作$A$，每个用户对应矩阵的一列，第$u$号用户对应矩阵的第$u$列记作向量$a_u$。</li>
<li>物品$embedding$层的参数是另一个矩阵，记作$B$，每个物品对应矩阵的一列，第$i$号物品对应矩阵的第$i$列,记作向量$b_i$。</li>
<li><strong>向量$a_u$ 和$b_i$ 的内积是第$u$号用户对第$i$号物品兴趣的预估值，内积越大，说明用户u对物品i的兴趣越强。</strong></li>
<li>训练模型的目的是学到矩阵$A$和$B$，使得预估值拟和真实观测的兴趣分数，矩阵$A$和$B$是$embedding$层的参数。<br><img src="/images/8_基本想法_1.png" alt="8_基本想法_1"></li>
</ul>
<h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>开始训练之前，首先要准备一个数据集，数据集是很多三元组的集合，每个三元组包含用户ID，物品ID，兴趣分数，意思是该用户对该物品真实的兴趣分数在系统里有记录，把数据集记作$\Omega=\{(u,i,y)\}$，$u$和$i$分别是用户ID和物品ID，y是真实观测的兴趣分数。数据集中的兴趣分数是系统记录的。这里举个例子，凡是有曝光的系统都会记录兴趣分数，曝光的意思是把物品展示给用户。如果有曝光，但是没有点击，说明不感兴趣，分数为零；如果有点击、点赞、收藏、转发，这些行为各算一分，这些行为都说明用户对物品感兴趣，那么兴趣分数最低是零分，最高是四分。<strong>训练的目的就是让模型的输出拟合兴趣分数</strong>。模型中有$embedding$层，可以把用户ID物品ID映射成向量。第$u$号用户映射成向量$a_u$，第$i$号物品映射成向量$b_i$。<br>训练的时候要求解这样一个优化问题，优化变量是矩阵$A$和$B$，它们是embedding层的参数。</p>
<script type="math/tex; mode=display">
min_{A,B} \sum_{(u,i,y)\in\Omega}(y-<a_u,b_i>)^2</script><p>仔细看一下公式，这里的三元组$（u，i，y）$是训练集中的一条数据，意思是用户$u$对物品$i$的真实兴趣分数是$y$。$ &lt; a_u,b_i &gt; $是向量$a_u$和$b_i$的内积，它是模型对兴趣分数的预估反应，第$u$号用户有多喜欢第$i$号物品。$(y- &lt; a_u,b_i &gt; )^2$是真实兴趣分数$y$与预估值之间的差，我们希望这个差越小越好，我们取差的平方，差的平方越小，则预估值越接近真实值$y$。对每一条记录的差的平方求和，作为优化的目标函数，对目标函数求最小化，优化的变量是矩阵$A$和$B$，求最小化可以用随机梯度下降等算法，每次更新矩阵$A$和$B$的一列，这样就可以学出矩阵$A$和$B$。<br>我来解释一下为什么这个模型叫做矩阵补充，看一下这个矩阵矩阵每一行对应一个用户，每一列对应一个物品，矩阵中的每个元素表示一个用户对一个物品的真实兴趣分数，系统里物品很多，一个用户看过的物品只是系统中的极少数，在矩阵中，绿色位置表示曝光给用户的物品，灰色位置表示没有曝光的物品。只要把物品曝光给用户，我们就知道用户对物品是否感兴趣，曝光了没点击说明不感兴趣，分数是零；曝光之后，用户可能会点击点赞，收藏转发，每个都算一分，加起来最多有四分。比如这个绿色位置表示第3号用户对第2号物品的兴趣分数等于四，矩阵中只有少数位置是绿色，大多数位置都是灰色，也就是没有曝光给用户的，我们并不知道用户对没曝光的物品是否感兴趣。我们刚才拿绿色位置的数据训练出了模型，有了模型，我们就可以预估出所有灰色位置的分数，也就是把矩阵的元素给补全，这就是为什么模型叫做矩阵补充。把矩阵元素补全之后，我们就可以做推荐，给定一个用户，我们选出用户对应的行中分数较高的物品推荐给该用户。<br><img src="/images/8_矩阵补充_1.png" alt="8_矩阵补充_1"></p>
<p>这节课介绍矩阵补充方法只是为了帮助大家理解向量召回而已，矩阵补充并不是工业界能work的方法，在实践中并不会用矩阵补充，我分析一下这种方法的缺点：</p>
<ol>
<li><strong>第一个缺点是矩阵补充没有利用物品属性和用户属性，矩阵补充仅仅用到了ID $embedding$ ,</strong>用两个$embedding$层分别把物品ID和用户ID设成两个向量。在小红书的场景下，物品属性包括类目关键词，地理位置，作者信息等等，用户属性包括性别年龄，地理定位，感兴趣的类目。知道这些属性召回可以做得更精准，下节课介绍双塔模型，可以看做矩阵补充模型的升级版，双塔模型不单单使用物品ID和用户ID，还会结合各种物品属性和用户属性，双塔模型的实际表现非常好。</li>
<li><strong>矩阵补充的第二个缺点是负样本的选取方式不对</strong>。样本指的是用户$u$和物品$i$的二元组，记作$(u,i)$。训练向量召回模型，需要正样本和负样本，矩阵补充的正样本指的是物品给用户曝光之后有点击交互的行为，这样的正样本是ok的，没问题，工业界都这么做，但是负样本的选取方式是完全错误的，矩阵补充的负样本是曝光之后没有点击交互的物品，这是一种想当然的做法，学术界的人可能以为这样没错，但可惜这样在实践中不work。后面我会专门用一节课讲解正负样本怎么选。</li>
<li><strong>第三个缺点是训练模型的方法不好</strong>，矩阵补充模型用向量$a_u$ 和$b_i$ 的内积作为兴趣分数的预估。这样没错，可以work，但是效果不如余弦相似度，工业界普遍使用余弦相似度，而不是用内积矩阵补充。用平方损失函数，也就是做回归，让预估的兴趣分数拟合真实的兴趣分数，这样做的效果不如交叉熵损失函数也就是做分类，工业界通常做分类，判定一个样本是正样本还是负样本。</li>
</ol>
<h2 id="线上服务"><a href="#线上服务" class="headerlink" title="线上服务"></a>线上服务</h2><p>这节课剩下内容都是线上服务，在训练好模型之后，可以把模型用作推荐系统中的召回通道，比如在用户刷小红书的时候，快速找到这个用户可能感兴趣的一两百篇笔记。</p>
<h3 id="模型存储"><a href="#模型存储" class="headerlink" title="模型存储"></a>模型存储</h3><p>做完训练之后，要把模型存储在正确的地方，便于做召回训练，得到矩阵$A$和$B$，他们是embedding层的参数，$A$的每一列对应一个用户，$B$的每一列对应一个物品。线上做推荐的时候，要用到矩阵$A$和$B$，这两个矩阵可能会很大，比如小红书有几亿用户，几亿篇笔记，那么这两个矩阵的列数都是好几亿，为了快速读取和快速查找，需要特殊的存储方式，把矩阵$A$的列存储到一张key-value表，存储的key值是用户的ID，value是矩阵$A$的一列，给定用户ID在表中做查找，得到一个向量，也就是该用户的embedding，另一个矩阵$B$也很大，$B$的存储和索引比较复杂，不能简单的用key-value存储，稍后我会解释原因以及解决方案。</p>
<p><img src="/images/8_模型存储_1.png" alt="8_模型存储_1"></p>
<p>在训练好模型，并且把$embedding$向量做存储之后，可以开始做线上服务。某用户刷小红书的时候，小红书的后台会开始做召回，把这位用户的ID作为key值查询，key-value表，得到该用户的$embedding$向量记作$a$，<strong>我们要查找用户最可能感兴趣的k个物品，作为召回结果，这叫做最近邻查找(nearest neighbor search)</strong>，把第$i$号物品的$embedding$向量记作$b_i$ ，计算用户向量$a$和物品向量$b_i$ 的内积，这是用户对第$i$号物品兴趣分数的预估，返回内积最大的k个物品，比如k等于100，这些物品就是召回的结果。<br>这种最近邻查找有个严重的问题，如果逐一对比所有物品时间复杂度会正比于物品数量，这种巨大的计算量是不可接受的，比如小红书有几亿篇笔记，那么就有几亿个向量$b$，逐一计算向量$a$和每个向量$b$的内积是不现实的，根本做不到线上的实时计算，这节课剩下的内容就是如何加速最近邻查找，避免暴力枚举。</p>
<h3 id="近似最近邻查找-Approximate-Nearest-Neighbor-Search"><a href="#近似最近邻查找-Approximate-Nearest-Neighbor-Search" class="headerlink" title="近似最近邻查找(Approximate Nearest Neighbor Search)"></a>近似最近邻查找(Approximate Nearest Neighbor Search)</h3><p>有很多算法加速最近邻查找，这些算法非常快，即使有几亿个物品，最多也只需要几万次内积，这些算法的结果未必是最优的，但是不会比最优结果差多少。<br>快速最近邻查找的算法已经被集成到很多向量数据库系统中，比较有名的包括Milvus、Faiss、HnswLib，做最近邻查找，需要定义什么是最近邻，也就是衡量最近邻的标准，比如最近邻可以定义为欧式距离最小的最近，你也可以定义为向量内积最大的，这叫做内积相似度，这节课的矩阵补充用的就是内积相似度，目前推荐系统最常用的是余弦相似度，其最近邻是向量夹角最小的，有些系统不支持余弦相似度，但这很好解决，如果你把所有向量都做归一化，让他们的二范数全都等于一，那么内积就等于余弦相似度。<br><img src="/images/8_最近邻查找_1.png" alt="8_最近邻查找_1"></p>
<p>我用一个直观的例子来演示最近邻查找。这是个散点图，每个点是一个物品的$embedding$向量，$embedding$向量都是训练模型的时候计算出来的，右边的五角星表示一个用户的$embedding$向量记作a，我们想要召回这个用户可能感兴趣的物品，这就需要计算向量a与所有点的相似度，如果用暴力枚举的话，计算量正比于点的数量，也就是物品的数量，想要减少最近邻查找的计算量，必须要避免暴力枚举。<br><img src="/images/8_最近邻查找_2.png" alt="8_最近邻查找_2"></p>
<p>这里介绍一种加速最近邻查找的办法，在做线上服务之前，先对数据做预处理，把数据划分成很多区域，比如这样划分，至于如何划分，取决于衡量最近邻的标准，如果是cos相似度，那么划分的结果就是这样的扇形，如果是用欧式距离，那么划分的结果就是多边形。<br><img src="/images/8_最近邻查找_3.png" alt=""></p>
<p>划分之后，每个区域用一个向量表示，比如这个蓝色区域用这个向量表示，比如这个黄色区域用这个向量表示，这些向量的长度都是一。划分区域之后建立索引，把每个区域的向量作为key，把区域中所有点的列表作为value，给定蓝色这个向量就能取回蓝色扇形区域中的所有的点。<br><img src="/images/8_最近邻查找_4.png" alt="8_最近邻查找_4"></p>
<p>划分区域之后，每个区域都用一个单位向量来表示，假如有一亿个点，那么划分成1万个区域，索引上一共有1万个k值，每个向量是一个区域的k值，给定一个向量可以快速取回这个区域内所有的点，有了这样一个索引就可以在线上快速做召回了。在线上给一个用户做推荐，这个用户的$embedding$向量记作$a$，我们首先把向量$a$跟索引中这些向量做对比，计算它们的相似度。如果物品数量是几亿，索引中的向量数量也只有几万而已，这一步的计算开销不大，计算相似度之后，我们发现索引中这个向量与$a$最相似，通过索引我们找到这个区域内所有的点，每个点对应一个物品。<br><img src="/images/8_最近邻查找_5.png" alt="8_最近邻查找_5">接下来我们计算点$a$跟区域内所有点的相似度，如果一共有几亿个物品被划分到了几万个区域，平均每个区域只有几万个点，所以这一步只需要计算几万次相似度，计算量也不大。假如我们想要找向量$a$最相似的三个点，也就是夹角最小的三个点，那么会找到这三个点，对应三个物品。这三个物品就是最近邻查找的结果，哪怕有几亿个物品，用这种近似算法做查找，也只需要计算几万次相似度，比暴力枚举快1万倍。<br><img src="/images/8_最近邻查找_6.png" alt="8_最近邻查找_6"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后总结一下这节课的内容，这节课主要介绍了矩阵补充模型，矩阵补充的想法是把物品ID和用户ID做embedding映射成两个向量，两个向量记作$a_u$和$b_i$。两者内积作为用户$u$对物品$i$兴趣的预估值。训练的时候，我们让$a_u$和$b_i$的内积拟合真实观测到的兴趣分数，用回归的方式学习模型中$embedding$层的参数。<br>矩阵补充是个学术界的模型，有很多缺点导致效果不好，工业界其实不用矩阵补充模型，而是用更先进的双塔模型。<br><img src="/images/8_总结_1.png" alt="8_总结_1"></p>
<p>假如用矩阵补充在线上做召回也是可以的，尽管效果不好，把用户向量$a$作为query，查找使得向量$a$和$b_i$内积最大化的物品$i$，寻找这样内积最大的top k物品$i$作为召回的结果。在工业界的场景下，有上亿物品，做暴力枚举的速度太慢了，不可行，实践中都用近似最近邻查找，不需要做枚举，我已经讲了近似最近邻查找的做法，工业界通常会用一些开源的向量数据库，比如Milvus、Faiss、HnswLib，这些向量数据库都会支持近似最近邻查找。<br><img src="/images/8_总结_2.png" alt="8_总结_2"><br>这节课就讲到这里，感谢大家观看，下节课讲双塔模型。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://syf1844803351.github.io">Syf</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://syf1844803351.github.io/2023/10/04/%E5%8F%AC%E5%9B%9E05%EF%BC%9A%E7%9F%A9%E9%98%B5%E8%A1%A5%E5%85%85%E3%80%81%E6%9C%80%E8%BF%91%E9%82%BB%E6%9F%A5%E6%89%BE/">https://syf1844803351.github.io/2023/10/04/%E5%8F%AC%E5%9B%9E05%EF%BC%9A%E7%9F%A9%E9%98%B5%E8%A1%A5%E5%85%85%E3%80%81%E6%9C%80%E8%BF%91%E9%82%BB%E6%9F%A5%E6%89%BE/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/10/09/%E5%8F%AC%E5%9B%9E06%EF%BC%9A%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E3%80%81%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95/" title="召回06：双塔模型——模型结构、训练方法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">召回06：双塔模型——模型结构、训练方法</div></div></a></div><div class="next-post pull-right"><a href="/2023/09/30/%E5%8F%AC%E5%9B%9E04%EF%BC%9A%E7%A6%BB%E6%95%A3%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86/" title="召回04：离散特征处理"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">召回04：离散特征处理</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Syf</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">34</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%8D%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">复习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">2.</span> <span class="toc-text">训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF"><span class="toc-number">2.1.</span> <span class="toc-text">基本思路</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.2.</span> <span class="toc-text">数据集</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E4%B8%8A%E6%9C%8D%E5%8A%A1"><span class="toc-number">3.</span> <span class="toc-text">线上服务</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%82%A8"><span class="toc-number">3.1.</span> <span class="toc-text">模型存储</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%91%E4%BC%BC%E6%9C%80%E8%BF%91%E9%82%BB%E6%9F%A5%E6%89%BE-Approximate-Nearest-Neighbor-Search"><span class="toc-number">3.2.</span> <span class="toc-text">近似最近邻查找(Approximate Nearest Neighbor Search)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">4.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/11/01/%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%9703%EF%BC%9ASIM%E6%A8%A1%E5%9E%8B%EF%BC%88%E9%95%BF%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1%EF%BC%89/" title="行为序列03：SIM模型（长序列建模）">行为序列03：SIM模型（长序列建模）</a><time datetime="2023-11-01T11:47:33.000Z" title="Created 2023-11-01 19:47:33">2023-11-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/11/01/%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%9702%EF%BC%9ADIN%E6%A8%A1%E5%9E%8B%EF%BC%88%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%89/" title="行为序列02：DIN模型（注意力机制）">行为序列02：DIN模型（注意力机制）</a><time datetime="2023-11-01T11:47:18.000Z" title="Created 2023-11-01 19:47:18">2023-11-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/11/01/%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%9701%EF%BC%9A%E7%94%A8%E6%88%B7%E5%8E%86%E5%8F%B2%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1/" title="行为序列01：用户历史行为序列建模">行为序列01：用户历史行为序列建模</a><time datetime="2023-11-01T11:44:14.000Z" title="Created 2023-11-01 19:44:14">2023-11-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/10/19/%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%8904%EF%BC%9ASENet%E5%92%8C%20Bilinear%E4%BA%A4%E5%8F%89/" title="特征交叉04：SENet和 Bilinear交叉">特征交叉04：SENet和 Bilinear交叉</a><time datetime="2023-10-19T11:56:20.000Z" title="Created 2023-10-19 19:56:20">2023-10-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/10/19/%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%8903%EF%BC%9ALHUC%EF%BC%88PPNet%EF%BC%89/" title="特征交叉03：LHUC（PPNet）">特征交叉03：LHUC（PPNet）</a><time datetime="2023-10-19T11:55:04.000Z" title="Created 2023-10-19 19:55:04">2023-10-19</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Syf</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>